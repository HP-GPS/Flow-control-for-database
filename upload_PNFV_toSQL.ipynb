{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import getpass\n",
    "import time\n",
    "\n",
    "# for collaboration\n",
    "username = getpass.getuser()\n",
    "username\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home and time\n",
    "home = Path.home()\n",
    "todaystr = date.today().strftime('%Y-%m-%d')\n",
    "# PNFV_alternative = pd.read_excel(Path(home, 'HP Inc', 'GPS TW Innovation - Documents', 'Users', 'GPS', 'PNFV', 'alternative.xlsx'))\n",
    "\n",
    "if username == 'panj':\n",
    "    PNFV = pd.read_excel(Path(home, 'HP Inc', 'GPS TW Innovation - 文件', 'Users', 'GPS', 'Shortage management related (Ri Xin)','PN FV description mapping table_ALL.xlsx')) # Jesse    \n",
    "else:    \n",
    "    PNFV = pd.read_excel(Path(home, 'HP Inc', 'GPS TW Innovation - Documents', 'Users', 'GPS', 'Shortage management related (Ri Xin)','PN FV description mapping table_ALL.xlsx')) # Dustin\n",
    "\n",
    "# someone keep upload duplicated rows\n",
    "PNFV = PNFV.drop_duplicates()\n",
    "PNFV = PNFV[['Commodity','Supplier','PN','Descr','Alternative part flag']]\n",
    "\n",
    "\"\"\"\n",
    "currently the folder for buyer to update is still in GPSTW SOP - 2021 日新\n",
    "REMEMBER to change the path when the folder officailly changed to GPS TW Innovation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the old part and upload new\n",
    "conn = pyodbc.connect('Driver={SQL Server Native Client 11.0}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# download from SQL\n",
    "cursor.execute(f\"SELECT * FROM OPS.GPS_tbl_ops_PN_FV\")\n",
    "PNFV_from_SQL = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "PNFV_from_SQL['alternative part flag'] = PNFV_from_SQL['alternative part flag'].replace({None: np.nan,'nan':np.nan})\n",
    "PNFV = PNFV.rename(columns={'Alternative part flag':'alternative part flag'})\n",
    "\n",
    "# find the rows need to upload and delete\n",
    "diff_df = PNFV_from_SQL.merge(PNFV, indicator=True, how='outer', on = ['Commodity','Supplier','PN','Descr','alternative part flag'])\n",
    "rows_to_delete = diff_df[diff_df['_merge'] == 'left_only']\n",
    "rows_to_insert = diff_df[diff_df['_merge'] == 'right_only']\n",
    "\n",
    "print(str(len(rows_to_delete)) + ' rows to delete')\n",
    "print(str(len(rows_to_insert)) + ' rows to upload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows from the SQL table that are not in the local DataFrame\n",
    "for index, row in rows_to_delete.iterrows():\n",
    "    cursor.execute(f\"DELETE FROM OPS.GPS_tbl_ops_PN_FV WHERE Commodity = ? AND Supplier = ? AND PN = ? AND Descr = ?\", \n",
    "                   row['Commodity'], row['Supplier'], row['PN'], row['Descr'])\n",
    "conn.commit()\n",
    "\n",
    "# Upload the local file rows to SQL table\n",
    "for index, row in rows_to_insert.iterrows():\n",
    "    # Directly use None for null values\n",
    "    commodity = row['Commodity'] if pd.notnull(row['Commodity']) else None\n",
    "    supplier = row['Supplier'] if pd.notnull(row['Supplier']) else None\n",
    "    pn = row['PN'] if pd.notnull(row['PN']) else None\n",
    "    descr = row['Descr'] if pd.notnull(row['Descr']) else None\n",
    "    alternative = row['alternative part flag'] if pd.notnull(row['alternative part flag']) else None\n",
    "\n",
    "    # Execute the insert statement with parameters\n",
    "    cursor.execute(\"INSERT INTO OPS.GPS_tbl_ops_PN_FV (Commodity, Supplier, PN, Descr, [alternative part flag]) VALUES (?, ?, ?, ?, ?)\", \n",
    "                commodity, supplier, pn, descr, alternative)\n",
    "    conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether upload successfully\n",
    "conn = pyodbc.connect('Driver={SQL Server Native Client 11.0}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# download from SQL\n",
    "cursor.execute(f\"SELECT * FROM OPS.GPS_tbl_ops_PN_FV\")\n",
    "PNFV_from_SQL_new = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "\n",
    "# check diff\n",
    "diff_df_new = PNFV_from_SQL_new.merge(PNFV, indicator=True, how='outer', on = ['Commodity','Supplier','PN','Descr'])\n",
    "rows_to_delete_new = diff_df_new[diff_df_new['_merge'] == 'left_only']\n",
    "rows_to_insert_new = diff_df_new[diff_df_new['_merge'] == 'right_only']\n",
    "\n",
    "# Check if there are no rows to delete or insert\n",
    "if rows_to_delete_new.empty and rows_to_insert_new.empty:\n",
    "    print('Records aligned, upload successfully!')\n",
    "else:\n",
    "    print('Please try again, something went wrong.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the timer\n",
    "end_time = time.time()\n",
    "print(\"The code used\", round(end_time-start_time,2), \"seconds, it is super fast!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the duplicated rows\n",
    "duplicate_rows = PNFV_from_SQL[PNFV_from_SQL.duplicated()]\n",
    "for index,row in duplicate_rows.iterrows():\n",
    "    delete_query = \"DELETE FROM CSI.OPS.GPS_tbl_ops_PN_FV WHERE Commodity =? AND Supplier=? AND PN=? AND Descr=? AND [alternative part flag]=?\"\n",
    "    cursor.execute(delete_query,(row['Commodity'],row['Supplier'],row['PN'],row['Descr'],str(row['alternative part flag'])))\n",
    "    if cursor.rowcount:\n",
    "        # print(row)\n",
    "        print(f\"{row['Commodity']},{row['Supplier']},{row['PN']},{row['Descr']} deleted from CSI.OPS.GPS_tbl_ops_PN_FV\")\n",
    "conn.commit()\n",
    "for index, row in duplicate_rows.iterrows():\n",
    "    s_Commodity = row['Commodity']\n",
    "    s_supplier = row['Supplier']\n",
    "    s_PN = row['PN']\n",
    "    s_descr = row['Descr']\n",
    "    s_alternative = str(row['alternative part flag'])\n",
    "\n",
    "    cursor.execute(f\"INSERT INTO CSI.OPS.GPS_tbl_ops_PN_FV (Commodity, Supplier, PN, Descr, [alternative part flag] )\\\n",
    "                    VALUES('{s_Commodity}','{s_supplier}','{s_PN}','{s_descr}','{s_alternative}')\".replace(\"'NaN'\", \"'NULL'\"))\n",
    "    if cursor.rowcount:\n",
    "        # print(row)\n",
    "        print(f\"{row['Commodity']},{row['Supplier']},{row['PN']},{row['Descr'] }uploaded to CSI.OPS.GPS_tbl_ops_PN_FV\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cadcbe1cf7f77607d04fb86883766795fe82998168b094e073d163801885097d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
