{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import win32com.client as win32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (date.today()- pd.DateOffset(days=1)).weekday() == 6:\n",
    "    today = (date.today()- pd.DateOffset(days=3)).strftime('%Y-%m-%d')\n",
    "else:\n",
    "    today = (date.today()- pd.DateOffset(days=1)).strftime('%Y-%m-%d')\n",
    "print(today)\n",
    "\n",
    "start_date = date.today() - pd.DateOffset(days=8)\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "print(start_date)\n",
    "#start_date  ='2024-10-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start=start_date, end=today)\n",
    "\n",
    "for single_date in date_range:\n",
    "    print(single_date.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = '2024-04-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_codes = [\n",
    "    \"Hub SB\",\n",
    "    \"WWSB\",\n",
    "    \"Broker buy\",\n",
    "    \"Return from ODM\",\n",
    "    \"To be re-programmed\",\n",
    "    \"To be sorted\",\n",
    "    \"To be qualified\",\n",
    "    \"FXN internal SB\",\n",
    "    \"Append EM\",\n",
    "    \"Navy deal\",\n",
    "    \"EOL without any supply\",\n",
    "    \"Waiver process\",\n",
    "    \"Others\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection\n",
    "conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "print('connect')\n",
    "\n",
    "# download shortge from SQL\n",
    "\n",
    "\n",
    "cursor.execute(f\"SELECT * FROM OPS.GPS_tbl_ops_shortage_ext where ReportDate >= '{start_date}' and ReportDate <= '{today}'\")\n",
    "shortage_ext = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "shortage_ext['HP_PN'] = shortage_ext['HP_PN'].str.replace('\\n', ',', regex=False)\n",
    "shortage_ext['FV'] = shortage_ext['FV'].str.replace('\\n', ',', regex=False)\n",
    "\n",
    "# download PNFV from SQL\n",
    "cursor.execute(\"SELECT * FROM OPS.GPS_tbl_ops_PN_FV\")\n",
    "PNFV = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "PNFV = PNFV.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
    "PNFV = PNFV.rename({'Descr':'FV'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PNFV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortage_ext['ReportDate'] = pd.to_datetime(shortage_ext['ReportDate'])\n",
    "\n",
    "# group bu commodity and count the len of each group\n",
    "shortage_ext = shortage_ext[shortage_ext['P1'] != 0]\n",
    "\n",
    "# CPU need to add supplier\n",
    "ext_CPU = shortage_ext[shortage_ext['Commodity'] == 'CPU']\n",
    "ext_CPU['Supplier'] = np.where(ext_CPU['FV'].str.contains('INTEL', case=False), 'INTEL', 'AMD')\n",
    "ext_CPU_group = ext_CPU.groupby(['ReportDate','Commodity','Supplier']).size().reset_index(name='Count')\n",
    "ext_CPU_group['Commodity'] = ext_CPU_group['Supplier'] + ' ' +  ext_CPU_group['Commodity']\n",
    "ext_CPU_group.drop(columns=['Supplier'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get internal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection\n",
    "conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "# download shortge from SQL\n",
    "cursor.execute(f\"SELECT * FROM OPS.GPS_view_ops_critical_shortage_overview WHERE [Report Date] >= '{start_date}' AND [Report Date] <= '{today}'\")\n",
    "internal = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "# check if there is empty value in Commodity\n",
    "if internal.Commodity.isna().any():\n",
    "    print(internal[internal.Commodity.isna()])\n",
    "else:\n",
    "    print('No empty value in Commodity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows with 'Delete' == 'Y' and group by Commodity\n",
    "internal = internal[(~(internal['Delete'] == 'Y'))]\n",
    "\n",
    "#drop internal P1 = 0 and na\n",
    "internal = internal.dropna(subset=['P1'])\n",
    "internal = internal[internal['P1'] != 0]\n",
    "\n",
    "internal.rename(columns={'Report Date': 'ReportDate'}, inplace=True)\n",
    "internal['ReportDate'] = pd.to_datetime(internal['ReportDate'])\n",
    "\n",
    "# CPU need to add supplier\n",
    "int_CPU = internal[internal['Commodity'] == 'CPU']\n",
    "int_CPU['Supplier'] = np.where(int_CPU['FV Des'].str.contains('INTEL', case=False), 'INTEL', 'AMD')\n",
    "int_CPU_group = int_CPU.groupby(['ReportDate','Commodity','Supplier']).size().reset_index(name='Count')\n",
    "int_CPU_group['Commodity'] = int_CPU_group['Supplier'] + ' ' +  int_CPU_group['Commodity']\n",
    "int_CPU_group.drop(columns=['Supplier'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special supply format misaligned (in reason_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_special_supply = internal.copy()\n",
    "#special supply is non supplier supply\n",
    "df_special_supply['ETA'] = df_special_supply['ETA'].str.split('\\n')\n",
    "df_special_supply = df_special_supply.explode('ETA')\n",
    "text = df_special_supply['ETA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conditions(text):\n",
    "   # 检查文本是否以 'ETA' 或 'TBD' 开头\n",
    "   if text is None:\n",
    "        return False\n",
    "   \n",
    "   if text.startswith('ETA') or text.startswith('TBD'):\n",
    "       return False\n",
    "   # 检查文本是否包含任何 reason_codes 中的字符串\n",
    "   for reason in reason_codes:\n",
    "       if reason in text:\n",
    "           return True\n",
    "   return False\n",
    "# 应用函数到 'ETA' 列\n",
    "df_special_supply['ETA misaligned'] = df_special_supply['ETA'].apply(check_conditions)\n",
    "# 打印结果\n",
    "print(df_special_supply)\n",
    "df_spsupply_true = df_special_supply[df_special_supply['ETA misaligned'] == True]\n",
    "df_spsupply_mis = df_spsupply_true[['ReportDate', 'Buyer Name', 'Commodity', 'FV Des', 'ETA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortage_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spsupply_mis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CQODM = ['CQQCI', 'CQIEC', 'CQWIS', 'TWIEC', 'L_WHFXN', 'CQPCQ', 'MSI', 'PCQ', 'PCP', 'WHFXN_L5', 'PSZ', 'FLH', 'TWQCI', 'SZBYD']\n",
    "WHODM = ['WHFXN']\n",
    "KSODM = ['CEI']\n",
    "THODM = ['THQCI','THIEC']\n",
    "MXODM = ['IMX']\n",
    "\n",
    "ODM_list = CQODM + WHODM + KSODM + THODM + MXODM\n",
    "\n",
    "incorrect_ODM = []\n",
    "for index in internal.index:\n",
    "    if internal.loc[index,'ODM'] not in ODM_list:\n",
    "        incorrect_ODM.append(internal.loc[index,:])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "incorrect_ODM = pd.DataFrame(incorrect_ODM)\n",
    "try:\n",
    "    incorrect_ODM = incorrect_ODM[['Report Date', 'Buyer Name','Commodity','ODM']]\n",
    "except:\n",
    "    pass\n",
    "\n",
    "incorrect_ODM = incorrect_ODM.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "print(len(incorrect_ODM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Commodity_list = ['AC ADAPTOR','AudioAMP','AudioCodec','BATTERY','CardReader','CHIPSET','CONNECTOR','CPU','EC','eMMC', 'Ethernet IC','GPU','GPU-Graphic Card','HDD','LanChip','LCD','Memory','NIC',\n",
    " 'ODD','POWERCORDS','PSU','Retimer','SIO','SSS','ThunderBT','TPM','TS','USBIC','VRAM','WEBCAM','WLAN','WWAN']\n",
    "\n",
    "incorrect_commodity = []\n",
    "for index in internal.index:\n",
    "    if internal.loc[index,'Commodity'] not in Commodity_list:\n",
    "        incorrect_commodity.append(internal.loc[index,:])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "incorrect_commodity = pd.DataFrame(incorrect_commodity)\n",
    "print(len(incorrect_commodity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (archive) merge and compare internal with external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_counts = internal.groupby(['ReportDate', 'Commodity']).size().reset_index(name='Count')\n",
    "# ext_count = shortage_ext.groupby(['ReportDate', 'Commodity']).size().reset_index(name='Count')\n",
    "# df_compare = int_counts[(int_counts['Commodity'] != 'CPU')].merge(ext_count[(ext_count['Commodity'] != 'CPU')],on=['ReportDate', 'Commodity'],how='outer',suffixes=('_int', '_ext'))\n",
    "# df_compare_CPU = int_CPU_group.merge(ext_CPU_group,on=['ReportDate','Commodity'],how='outer',suffixes=('_int', '_ext'))\n",
    "# df_compare = pd.concat([df_compare, df_compare_CPU], axis=0)\n",
    "# df_compare = df_compare.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mismatch_total = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for report_date, group in df_compare.groupby('ReportDate'):\n",
    "#     df_mismatch = group[((group['Count_int'].isnull()) & (group['Count_ext'].notnull())) | ((group['Count_int'].notnull()) & (group['Count_ext'].isnull()))]\n",
    "#     df_mismatch.loc[:, ['Count_int', 'Count_ext']] = df_mismatch.loc[:, ['Count_int', 'Count_ext']].fillna(0)\n",
    "#     df_mismatch.set_index('Commodity', inplace=True)\n",
    "#     df_mismatch[['Count_int', 'Count_ext']] = df_mismatch[['Count_int', 'Count_ext']].astype(int)\n",
    "#     df_mismatch.rename(columns={'Count_int': 'Count_internal', 'Count_ext': 'Count_external'}, inplace=True)\n",
    "#     df_mismatch = df_mismatch[df_mismatch.index != 'Ethernet IC']\n",
    "#     df_mismatch['ReportDate'] = report_date\n",
    "#     df_mismatch_total = pd.concat([df_mismatch_total, df_mismatch], axis=0)\n",
    "\n",
    "# df_mismatch_total.reset_index(inplace=True)\n",
    "# df_mismatch_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### misalignment in HP_PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal/external data for HP_PN check\n",
    "internal_pn = internal[['ReportDate', 'Commodity', 'HP Part Number', 'Buyer Name']].drop_duplicates()\n",
    "internal_pn = internal_pn.rename(columns={'HP Part Number': 'HP_PN', 'Buyer Name': 'BuyerName'})\n",
    "external_pn = shortage_ext[['ReportDate', 'Commodity', 'HP_PN', 'BuyerName']].drop_duplicates()\n",
    "\n",
    "\n",
    "# prcoess HP_PN format\n",
    "def preprocess_pn(df):\n",
    "    df['HP_PN'] = df['HP_PN'].astype(str).str.replace(' ', ',', regex=False)\n",
    "    df['HP_PN'] = df['HP_PN'].str.replace('\\n', '', regex=False)\n",
    "    df = df.explode('HP_PN').reset_index(drop=True)\n",
    "    df['HP_PN'] = df['HP_PN'].astype(str).str.strip().str[:6]\n",
    "    df = df[df['HP_PN'].notna() & (df['HP_PN'] != '')]\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "internal_pn = preprocess_pn(internal_pn)\n",
    "external_pn = preprocess_pn(external_pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first-level comparison: use ReportDate+Commodity+HP_PN as key \n",
    "df_mismatch_pn = pd.merge(internal_pn, external_pn, on=['ReportDate', 'Commodity', 'HP_PN'], how='outer', indicator=True)\n",
    "df_mismatch_pn['BuyerName'] = df_mismatch_pn['BuyerName_y'].combine_first(df_mismatch_pn['BuyerName_x'])\n",
    "df_mismatch_pn_both = df_mismatch_pn[df_mismatch_pn['_merge'] == 'both']\n",
    "\n",
    "\n",
    "# second-level comparison(for those mismatched ): use ReportDate+Commodity+Buyername as key\n",
    "to_remove_internal = df_mismatch_pn_both.groupby(['ReportDate', 'Commodity', 'BuyerName_x']).size().reset_index(name='count')\n",
    "to_remove_internal = to_remove_internal[to_remove_internal['count'] >= 1][['ReportDate', 'Commodity', 'BuyerName_x']]\n",
    "to_remove_external = df_mismatch_pn_both.groupby(['ReportDate', 'Commodity', 'BuyerName_y']).size().reset_index(name='count')\n",
    "to_remove_external = to_remove_external[to_remove_external['count'] >= 1][['ReportDate', 'Commodity', 'BuyerName_y']]\n",
    "\n",
    "df_mismatch_pn = df_mismatch_pn.loc[\n",
    "    ~df_mismatch_pn[['ReportDate', 'Commodity', 'BuyerName_x']].apply(tuple, axis=1).isin(to_remove_internal.apply(tuple, axis=1)) &\n",
    "    ~df_mismatch_pn[['ReportDate', 'Commodity', 'BuyerName_y']].apply(tuple, axis=1).isin(to_remove_external.apply(tuple, axis=1))]\n",
    "\n",
    "\n",
    "# clean the format\n",
    "df_mismatch_pn = df_mismatch_pn.groupby(['ReportDate', 'Commodity', 'BuyerName', '_merge'], observed=True).agg({'HP_PN': lambda x: ', '.join(x)}).reset_index()\n",
    "df_mismatch_pn['Missing PN in'] = df_mismatch_pn['_merge'].map({'right_only': 'Internal: ', 'left_only': 'External: '}) + df_mismatch_pn['HP_PN']\n",
    "\n",
    "df_mismatch_pn = df_mismatch_pn.drop(columns=['HP_PN', '_merge', 'BuyerName'])\n",
    "df_mismatch_pn = df_mismatch_pn.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "To_list = 'gps.taiwan.nb.buy-sell@hp.com'\n",
    "CC_list = 'spencer.cheng1@hp.com; howie.chang1@hp.com; frederick.shih@hp.com; bspott@hp.com'\n",
    "\n",
    "mail = win32.Dispatch(\"Outlook.Application\").CreateItem(0)\n",
    "mail.To = To_list\n",
    "mail.CC = CC_list\n",
    "mail.Subject = f'Internal/ External Report Misalignment alert <From Report Date: {start_date} to {today}>'\n",
    "\n",
    "message = f\"\"\"Hi team,<br><br>\"\"\"\n",
    "\n",
    "if len(df_mismatch_pn) > 0 or len(incorrect_ODM) > 0 or len(incorrect_commodity) > 0 or len(df_spsupply_mis) > 0:\n",
    "    message += f\"\"\"The following shows misalignment in external & internal reports, or incorrect data in internal reports from the report date: <b><font color=\"blue\">{start_date}</b></font>, \n",
    "    please review and make the necessary amendments.<br><br>\"\"\"\n",
    "\n",
    "    if len(df_mismatch_pn) > 0:\n",
    "        message += f\"\"\"Below data contains <b><font color=\"blue\">misaligned/ missing data in external & internal reports</b></font>, please upload missing values or correct errors.<br><font color=\"gray\">\n",
    "        <u>Note: If any below PNs have P1 set to 0 in either external or internal report due to the sorting issue, please ignore the alert.</u></font><br>\n",
    "        {df_mismatch_pn.to_html(escape=False, index=False)}<br><br>\"\"\"\n",
    "\n",
    "    if len(incorrect_ODM) > 0:\n",
    "        incorrect_ODM['ODM'] = incorrect_ODM['ODM'].apply(lambda name: f'<font color=\"Red\">{name}</font>')\n",
    "        message += f\"\"\"Below data contains <b><font color=\"blue\">incorrect ODM name</b></font>in internal reports, please delete the data and upload again with the correct ODM name.<br>\n",
    "        {incorrect_ODM.to_html(escape=False, index=False)}<br><br>\"\"\"\n",
    "\n",
    "    if len(incorrect_commodity) > 0:\n",
    "        incorrect_commodity['Commodity'] = incorrect_commodity['Commodity'].apply(lambda name: f'<font color=\"Red\">{name}</font>')\n",
    "        message += f\"\"\"Below data contains <b><font color=\"blue\">incorrect Commodity name</b></font>, please delete the data and upload again with the correct Commodity name.<br>\n",
    "        {incorrect_commodity.to_html(escape=False, index=False)}<br><br>\"\"\"\n",
    "\n",
    "    if len(df_spsupply_mis) > 0:\n",
    "        message += f\"\"\"Below data contains <b><font color=\"blue\">non-supplier supply with incorrect format</b></font>, please update the data with internal shortage tool accordingly.<br>\n",
    "        {df_spsupply_mis.to_html(escape=False, index=False)}<br><br>\"\"\"\n",
    "\n",
    "if len(df_mismatch_pn) == 0 and len(incorrect_ODM) == 0 and len(incorrect_commodity) == 0 and len(df_spsupply_mis) == 0:\n",
    "    message = f\"\"\"Hi team,<br><br>\n",
    "    No information is <b><font color=\"blue\">misaligned/ missing</b></font> in external & internal reports or incorrect data in internal reports from report date: <b><font color=\"blue\">{start_date} to {today}</b></font>.<br><br>\"\"\"\n",
    "\n",
    "message += \"\"\"If you have any questions or need assistance, please feel free to log a ticket through the following link: \n",
    "<a href=\"https://forms.office.com/pages/responsepage.aspx?id=ooF5ylp4PUa4Kj24ffw85u5RnrVmIrxMqwWn4XKOaL9UNlRST1VDQUtUTVA5VDhTTzlBU1lGRjdaNy4u&origin=lprLink&route=shorturl\">Digital tool issue ticket</a>.<br>\n",
    "Thank you.<br><br>\"\"\"\n",
    "\n",
    "\n",
    "signature = \"\"\"<br><br><font color=\"black\">Best Regards,<br>Operations Transformation Team</font>\"\"\"\n",
    "\n",
    "mail.GetInspector\n",
    "index = mail.HTMLbody.find('>', mail.HTMLbody.find('<body'))\n",
    "mail.HTMLBody = message + signature\n",
    "mail.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection\n",
    "conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server}; Server=g7w11206g.inc.hpicorp.net; Database=CSI; Trusted_Connection=Yes;')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# download shortge from SQL\n",
    "cursor.execute(f\"SELECT * FROM OPS.GPS_view_ops_critical_shortage_overview where [Report Date] = '{today}'\")\n",
    "shor = pd.DataFrame.from_records(cursor.fetchall(), columns = [i[0] for i in cursor.description])\n",
    "conn.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
