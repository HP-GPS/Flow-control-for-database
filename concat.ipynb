{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 導入套件 + 設定路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from datetime import date\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# home and time\n",
    "home = Path.home()\n",
    "todaystr = date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# set up concat directories\n",
    "targetFolder = Path(home, 'HP Inc','GPSTW SOP - 2021 日新','Project team','Upload folder ( for buyer update )')\n",
    "FD_folder = Path(targetFolder, \"FD_today\",\"*.xlsx\")\n",
    "shortage_folder = Path(targetFolder ,\"shortage_today\",\"*.xlsx\")\n",
    "PNbasedDetail_folder = Path(targetFolder ,\"PNbasedDetail_today\",\"*.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD 合併以及整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合併檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat FD\n",
    "FD_files = []\n",
    "for FD_file in glob.glob(str(Path(FD_folder))):\n",
    "    print(FD_file)\n",
    "    FD = pd.read_excel(FD_file)\n",
    "    FD_files.append(FD)\n",
    "FD_all = pd.concat(FD_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember inplace = True\n",
    "FD_all['len_FV'] = FD_all['FV'].str.len()\n",
    "FD_all['len_platform'] = FD_all['Platform'].str.len()\n",
    "FD_all = FD_all.sort_values(['len_FV','len_platform'] , ascending=[False,False])\n",
    "FD_all.reset_index( drop = True, inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將max len放到前方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index where B is longest\n",
    "FD_idmax = FD_all['len_platform'].max()\n",
    "df_max = FD_all.loc[FD_all['len_platform'] == FD_idmax]\n",
    "df_max_to_add_FD = df_max.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isin用在list\n",
    "# drop the max len row\n",
    "FD_all = FD_all.drop([FD_all.index[df_max_to_add_FD.index.values[0]]]).reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat and put the max len row on the top\n",
    "FD_concat = [df_max_to_add_FD,FD_all]\n",
    "FD_output = pd.concat(FD_concat)\n",
    "FD_output.reset_index( drop = True , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut more than 500\n",
    "FD_output['Platform'] = FD_output['Platform'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "FD_output = FD_output.drop( columns= ['len_FV','len_platform'])\n",
    "FD_output['Item'] = FD_output['Item'].astype(str)\n",
    "FD_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortage 合併以及整理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合併檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat shortage\n",
    "shortage_files = []\n",
    "for shortage_file in glob.glob(str(Path(shortage_folder))):\n",
    "    print(shortage_file)\n",
    "    shortage = pd.read_excel(shortage_file)\n",
    "    shortage_files.append(shortage)\n",
    "shortage_all = pd.concat(shortage_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create value to sort \n",
    "shortage_all['len_FV'] = shortage_all['FV'].str.len()\n",
    "shortage_all['len_platform'] = shortage_all['Platform'].str.len()\n",
    "shortage_all = shortage_all.sort_values(['len_FV','len_platform'] , ascending=[False,False])\n",
    "shortage_all.reset_index( drop = True, inplace = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 將max len放到前面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max length \n",
    "shortage_idmax = shortage_all['len_platform'].max()\n",
    "shortage_max = shortage_all.loc[shortage_all['len_platform'] == shortage_idmax]\n",
    "df_max_to_add_shortage = shortage_max.head(1)\n",
    "df_max_to_add_shortage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the max len row\n",
    "shortage_all = shortage_all.drop([shortage_all.index[df_max_to_add_shortage.index.values[0]]]).reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat and put the max len row on the top\n",
    "shortage_concat = [ df_max_to_add_shortage , shortage_all ]\n",
    "shortage_output = pd.concat(shortage_concat)\n",
    "shortage_output.reset_index( drop = True , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut more than 500\n",
    "shortage_output['Platform'] = shortage_output['Platform'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "shortage_output = shortage_output.drop( columns= ['len_FV','len_platform'])\n",
    "shortage_output['Item'] = shortage_output['Item'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PNbasedDetail 合併及整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat PNbasedDetail\n",
    "PNbasedDetail_files = []\n",
    "for PNbasedDetail_file in glob.glob(str(Path(PNbasedDetail_folder))):\n",
    "    print(PNbasedDetail_file)\n",
    "    PNbasedDetail = pd.read_excel(PNbasedDetail_file)\n",
    "    PNbasedDetail_files.append(PNbasedDetail)\n",
    "PNbasedDetail_all = pd.concat(PNbasedDetail_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list to sort \n",
    "sort_list = []\n",
    "asc_list = []\n",
    "\n",
    "try:\n",
    "    PNbasedDetail_all['len_GPS Remark'] = PNbasedDetail_all['GPS Remark'].str.len()\n",
    "    sort_list.append('len_GPS Remark')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_all['len_ODM use column1'] = PNbasedDetail_all['ODM use column1'].str.len()\n",
    "    sort_list.append('len_ODM use column1')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_all['len_ODM use column2'] = PNbasedDetail_all['ODM use column2'].str.len()\n",
    "    sort_list.append('len_ODM use column2')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_all['len_ODM use column3'] = PNbasedDetail_all['ODM use column3'].str.len()\n",
    "    sort_list.append('len_ODM use column3')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_all['len_ODM use column4'] = PNbasedDetail_all['ODM use column4'].str.len()\n",
    "    sort_list.append('len_ODM use column4')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_all['len_ODM use column5'] = PNbasedDetail_all['ODM use column5'].str.len()\n",
    "    sort_list.append('len_ODM use column5')\n",
    "    asc_list.append(True)\n",
    "except:    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort value\n",
    "PNbasedDetail_all = PNbasedDetail_all.sort_values( sort_list , ascending = asc_list )\n",
    "PNbasedDetail_all.reset_index( drop=True , inplace=True ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the max length & concat\n",
    "PNbasedDetail_max_files = []\n",
    "\n",
    "# a for loop to calculate all the len max\n",
    "for i in range( 1 , len(sort_list) ):\n",
    "    PNbasedDetail_idmax = PNbasedDetail_all [ sort_list[i] ].max()\n",
    "    PNbasedDetail_max = PNbasedDetail_all.loc[ PNbasedDetail_all[ sort_list[i] ] == PNbasedDetail_idmax ]\n",
    "    PNbasedDetail_max_files.append( PNbasedDetail_max.head(1) )\n",
    "    df_max_to_add_PNbasedDetail_temp = pd.concat( PNbasedDetail_max_files )\n",
    "\n",
    "# sometimes with duplicates \n",
    "df_max_to_add_PNbasedDetail = df_max_to_add_PNbasedDetail_temp.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_max_to_add_PNbasedDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the max len row\n",
    "for i in range( 0, len(df_max_to_add_PNbasedDetail.index.values)):\n",
    "    PNbasedDetail_all = PNbasedDetail_all.drop([PNbasedDetail_all.index[df_max_to_add_PNbasedDetail.index.values[i]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat and put on the top\n",
    "PNbasedDetail_concat_list = [ df_max_to_add_PNbasedDetail , PNbasedDetail_all ]\n",
    "PNbasedDetail_output = pd.concat(PNbasedDetail_concat_list).reset_index( drop = True )\n",
    "PNbasedDetail_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut more than 500\n",
    "try:\n",
    "    PNbasedDetail_output['GPS Remark'] = PNbasedDetail_output['GPS Remark'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_output['ODM use column1'] = PNbasedDetail_output['ODM use column1'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_output['ODM use column2'] = PNbasedDetail_output['ODM use column2'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_output['ODM use column3'] = PNbasedDetail_output['ODM use column3'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_output['ODM use column4'] = PNbasedDetail_output['ODM use column4'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n",
    "try:\n",
    "    PNbasedDetail_output['ODM use column5'] = PNbasedDetail_output['ODM use column5'].apply(lambda x: x[:450] if len(x) > 500 else x)\n",
    "except:    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final step, drop calculate step and output\n",
    "PNbasedDetail_output = PNbasedDetail_output.drop( columns = sort_list )\n",
    "PNbasedDetail_output['Item'] = PNbasedDetail_output['Item'].astype(str)\n",
    "PNbasedDetail_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD、Shortage、PNbasedDetail 輸出檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apache airflow to upload SQL ( currently to desktop )\n",
    "FD_output.to_excel(Path(home, 'Desktop', 'FD_all.xlsx'), index=False)\n",
    "shortage_output.to_excel(Path(home, 'Desktop', 'Shortage_all.xlsx'), index=False)\n",
    "PNbasedDetail_output.to_excel(Path(home, 'Desktop', 'PNbasedDetail_all.xlsx'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0340fd9be07f79e7fee6f89041a304fd85cd99d2adddc5ff8ceed550ac7e8fe0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
